{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4059f4be-1032-42a2-99e2-a0cde7c2ae97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.159  Python-3.13.5 torch-2.7.1+cpu CPU (Intel Core(TM) i5-6300U 2.40GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\Tumor Detection.v8i.yolov11\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=416, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431647  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,815 parameters, 2,590,799 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.30.3 ms, read: 79.728.8 MB/s, size: 34.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\Tumor Detection.v8i.yolov11\\train\\labels.cache...\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\Tumor Detection.v8i.yolov11\\train\\images\\no_tumor_914_jpg.rf.6714544aee2bde5213fd2c366dff62aa.jpg: 1 duplicate labels removed\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 1456, len(boxes) = 1461. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 101.631.1 MB/s, size: 29.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Usman Pc\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\Tumor Detection.v8i.yolov11\\valid\\labels.cache... 3\u001b[0m\n",
      "C:\\Users\\Usman Pc\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train3\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G     0.9072      2.742      1.152         19        416: 100%|██████████| 86/86 [16:23<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [01:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.883      0.256      0.377      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20         0G     0.9436      1.537      1.128         21        416: 100%|██████████| 86/86 [08:06<00:00,  5.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:54"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.707      0.523      0.497      0.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20         0G     0.9639      1.394      1.138         27        416: 100%|██████████| 86/86 [07:14<00:00,  5.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.668      0.458      0.466      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20         0G     0.9579      1.282      1.144         29        416: 100%|██████████| 86/86 [06:56<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:46"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.832      0.424      0.543      0.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20         0G     0.9016      1.181       1.11         19        416: 100%|██████████| 86/86 [06:48<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:44"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415       0.76      0.572      0.583      0.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20         0G     0.8816      1.072      1.108         13        416: 100%|██████████| 86/86 [06:37<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:43"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415       0.75      0.579      0.584      0.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20         0G     0.8627      1.015      1.098         15        416: 100%|██████████| 86/86 [06:45<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:45"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.805      0.561      0.621      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20         0G     0.8592     0.9733       1.09         12        416: 100%|██████████| 86/86 [06:32<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:44"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.704       0.58      0.586      0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20         0G     0.8074     0.9017      1.077         13        416: 100%|██████████| 86/86 [06:18<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:41"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.809      0.599      0.619      0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20         0G      0.803     0.8847      1.077         21        416: 100%|██████████| 86/86 [06:09<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:41"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.777      0.613      0.622       0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usman Pc\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "      11/20         0G     0.7098     0.8749      1.042         10        416: 100%|██████████| 86/86 [06:05<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:41"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.789      0.631      0.636      0.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20         0G     0.7024     0.8152      1.034         14        416: 100%|██████████| 86/86 [8:18:55<00:00, 3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [01:57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.812      0.607      0.625      0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20         0G     0.6537     0.7634      1.006         10        416: 100%|██████████| 86/86 [10:07<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [01:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.828      0.582      0.625      0.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20         0G     0.6406     0.7236      0.996         10        416: 100%|██████████| 86/86 [08:17<00:00,  5.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:56"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.857      0.591      0.646      0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20         0G      0.615     0.6674     0.9897         13        416: 100%|██████████| 86/86 [08:44<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:58"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.827      0.616       0.64      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20         0G     0.6043     0.6533     0.9879         10        416: 100%|██████████| 86/86 [1:29:50<00:00, 6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [02:16"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.898      0.598      0.661      0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20         0G      0.581     0.6176     0.9625         10        416: 100%|██████████| 86/86 [16:16<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [02:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.881      0.592      0.659      0.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20         0G     0.5577      0.586     0.9662         12        416: 100%|██████████| 86/86 [10:45<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.826      0.627      0.644       0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20         0G     0.5464     0.5528     0.9578         10        416: 100%|██████████| 86/86 [06:24<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:44"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.838      0.613      0.649      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20         0G     0.5342     0.5368      0.946         12        416: 100%|██████████| 86/86 [06:56<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:44"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.826       0.64      0.652      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 12.684 hours.\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\last.pt, 5.4MB\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\best.pt, 5.4MB\n",
      "\n",
      "Validating runs\\detect\\train3\\weights\\best.pt...\n",
      "Ultralytics 8.3.159  Python-3.13.5 torch-2.7.1+cpu CPU (Intel Core(TM) i5-6300U 2.40GHz)\n",
      "YOLO11n summary (fused): 100 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        395        415      0.881      0.592       0.66      0.528\n",
      "              NO_tumor        115        116      0.964      0.917      0.982      0.811\n",
      "                glioma         30         36      0.761        0.5      0.597      0.377\n",
      "            meningioma        144        148      0.921      0.885      0.944      0.823\n",
      "             pituitary        106        111       0.76      0.658      0.778      0.629\n",
      "space-occupying lesion-          1          4          1          0          0          0\n",
      "Speed: 2.1ms preprocess, 109.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "     from ultralytics import YOLO\n",
    "\n",
    "     # Load model\n",
    "     model = YOLO(r\"C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\yolo11n.pt\")  # Full path to model\n",
    "\n",
    "     # Train model\n",
    "     train_results = model.train(\n",
    "         data=r\"C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\Tumor Detection.v8i.yolov11\\data.yaml\",\n",
    "         epochs=20,\n",
    "         imgsz=416,\n",
    "         device=\"cpu\", \n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97b8cefb-1292-4347-85e6-1b56f4b1cd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\test_images\\download (2).jpeg: 416x384 1 NO_tumor, 138.8ms\n",
      "Speed: 4.9ms preprocess, 138.8ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\runs\\\\detect\\\\train3\\\\weights\\\\best.pt\")\n",
    "result = model(\"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\test_images\\\\download (2).jpeg\", save = True)\n",
    "result[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8da797e-cfd1-445d-bbd1-956edd942cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exists: True\n",
      "Image exists: True\n",
      "\n",
      "image 1/1 C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\test_images\\download (1).jpeg: 416x352 1 NO_tumor, 101.5ms\n",
      "Speed: 7.4ms preprocess, 101.5ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 352)\n",
      "Results saved to \u001b[1mruns\\detect\\predict6\u001b[0m\n",
      "Number of results: 1\n",
      "Detections: ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.8998])\n",
      "data: tensor([[ 19.1206,  45.9460, 173.6395, 214.0691,   0.8998,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (252, 200)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[ 96.3801, 130.0076, 154.5189, 168.1231]])\n",
      "xywhn: tensor([[0.4819, 0.5159, 0.7726, 0.6672]])\n",
      "xyxy: tensor([[ 19.1206,  45.9460, 173.6395, 214.0691]])\n",
      "xyxyn: tensor([[0.0956, 0.1823, 0.8682, 0.8495]])\n",
      "Output image saved at: C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\runs\\detect\\last.pt\\download_1.jpeg\n",
      "Output image not found. Listing directory contents:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File paths\n",
    "model_path = \"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\runs\\\\detect\\\\train3\\\\weights\\\\best.pt\"\n",
    "image_path = \"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\test_images\\\\download (1).jpeg\"\n",
    "output_dir = \"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\runs\\\\detect\\\\last.pt\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Verify paths\n",
    "print(\"Model exists:\", os.path.exists(model_path))\n",
    "print(\"Image exists:\", os.path.exists(image_path))\n",
    "\n",
    "# Load model and run inference\n",
    "model = YOLO(model_path)\n",
    "results = model(image_path, save=True, save_dir=output_dir, conf=0.1, verbose=True)\n",
    "\n",
    "# Print results\n",
    "print(\"Number of results:\", len(results))\n",
    "print(\"Detections:\", results[0].boxes if results[0].boxes else \"No detections\")\n",
    "\n",
    "# Get output image path (replace spaces and parentheses in filename)\n",
    "output_filename = os.path.basename(image_path).replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "output_image_path = os.path.join(output_dir, output_filename)\n",
    "print(\"Output image saved at:\", output_image_path)\n",
    "\n",
    "# Display using Matplotlib\n",
    "if os.path.exists(output_image_path):\n",
    "    img = cv2.imread(output_image_path)\n",
    "    if img is not None:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Failed to load saved image.\")\n",
    "else:\n",
    "    print(\"Output image not found. Listing directory contents:\")\n",
    "    print(os.listdir(output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f4a381-02d7-4a04-aaee-93617089ce17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a96d8a1-b116-440f-900d-3eff8a46ff29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Usman Pc\\AppData\\Local\\Temp\\ipykernel_5268\\1473781204.py:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  result = model(\"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\sam2_yolo11\\\\sam_yolo11\\\\test_images\", save = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/6 C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\test_images\\download (1).jpeg: 416x352 1 NO_tumor, 111.0ms\n",
      "image 2/6 C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\test_images\\download (2).jpeg: 416x384 1 NO_tumor, 98.0ms\n",
      "image 3/6 C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\test_images\\download (3).jpeg: 416x416 (no detections), 115.8ms\n",
      "image 4/6 C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\test_images\\download.jpeg: 416x416 1 NO_tumor, 105.3ms\n",
      "image 5/6 C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\test_images\\images.jpeg: 416x416 2 NO_tumors, 101.8ms\n",
      "image 6/6 C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\test_images\\test_tumor.jpeg: 416x384 1 meningioma, 91.9ms\n",
      "Speed: 2.7ms preprocess, 104.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\runs\\\\detect\\\\train3\\\\weights\\\\best.pt\")\n",
    "result = model(\"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\sam2_yolo11\\\\sam_yolo11\\\\test_images\", save = True)\n",
    "result[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375fdc2-f3f7-424a-85c2-667d8aa2cfc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "412d9ccf-13f3-4ce2-bd72-46570e020ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\test_images\\download (3).jpeg: 416x416 (no detections), 134.2ms\n",
      "Speed: 2.7ms preprocess, 134.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\predict7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\runs\\\\detect\\\\train3\\\\weights\\\\best.pt\")\n",
    "result = model(\"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\test_images\\\\download (3).jpeg\", save = True)\n",
    "result[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13b1f1e7-eac7-4735-becf-cfc9efe37647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exists: True\n",
      "Image exists: True\n",
      "\n",
      "image 1/1 C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\test_images\\test_tumor.jpeg: 416x384 1 meningioma, 133.5ms\n",
      "Speed: 2.6ms preprocess, 133.5ms inference, 2.4ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Results saved to \u001b[1mruns\\detect\\predict8\u001b[0m\n",
      "Number of results: 1\n",
      "Detections: ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.9486])\n",
      "data: tensor([[120.1688,  97.2786, 170.1015, 153.0472,   0.9486,   2.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (239, 211)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[145.1351, 125.1629,  49.9327,  55.7686]])\n",
      "xywhn: tensor([[0.6878, 0.5237, 0.2366, 0.2333]])\n",
      "xyxy: tensor([[120.1688,  97.2786, 170.1015, 153.0472]])\n",
      "xyxyn: tensor([[0.5695, 0.4070, 0.8062, 0.6404]])\n",
      "Detected classes: ['meningioma']\n",
      "Output image saved at: C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\runs\\detect\\predict7\\test_tumor.jpeg\n",
      "Output image not found. Directory contents: []\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "model_path = \"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\runs\\\\detect\\\\train3\\\\weights\\\\best.pt\"\n",
    "image_path = \"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\test_images\\\\test_tumor.jpeg\"  # Update to your tumor image\n",
    "output_dir = \"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\runs\\\\detect\\\\predict7\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Verify paths\n",
    "print(\"Model exists:\", os.path.exists(model_path))\n",
    "print(\"Image exists:\", os.path.exists(image_path))\n",
    "\n",
    "# Load model and run inference\n",
    "model = YOLO(model_path)\n",
    "results = model(image_path, save=True, save_dir=output_dir, conf=0.05, verbose=True)  # Lower confidence threshold\n",
    "\n",
    "# Print results\n",
    "print(\"Number of results:\", len(results))\n",
    "print(\"Detections:\", results[0].boxes if results[0].boxes else \"No detections\")\n",
    "if results[0].boxes:\n",
    "    print(\"Detected classes:\", [model.names[int(cls)] for cls in results[0].boxes.cls])\n",
    "\n",
    "# Get output image path\n",
    "output_filename = os.path.basename(image_path)  # Use exact filename (e.g., test_tumor.jpg)\n",
    "output_image_path = os.path.join(output_dir, output_filename)\n",
    "print(\"Output image saved at:\", output_image_path)\n",
    "\n",
    "# Display using Matplotlib\n",
    "if os.path.exists(output_image_path):\n",
    "    img = cv2.imread(output_image_path)\n",
    "    if img is not None:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Failed to load saved image.\")\n",
    "else:\n",
    "    print(\"Output image not found. Directory contents:\", os.listdir(output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98cbc589-4944-4c51-be1b-78f635311690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\test_images\\test_tumor.jpeg: 416x384 1 meningioma, 115.0ms\n",
      "Speed: 4.2ms preprocess, 115.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 384)\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.9486])\n",
      "data: tensor([[120.1688,  97.2786, 170.1015, 153.0472,   0.9486,   2.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (239, 211)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[145.1351, 125.1629,  49.9327,  55.7686]])\n",
      "xywhn: tensor([[0.6878, 0.5237, 0.2366, 0.2333]])\n",
      "xyxy: tensor([[120.1688,  97.2786, 170.1015, 153.0472]])\n",
      "xyxyn: tensor([[0.5695, 0.4070, 0.8062, 0.6404]])\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\runs\\\\detect\\\\train3\\\\weights\\\\best.pt\")\n",
    "result = model(\"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\test_images\\\\test_tumor.jpeg\")\n",
    "for result in results:\n",
    "    boxes=result.boxes\n",
    "    print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb88aa7b-b8d3-4c18-8cd1-35dd212d4e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exists: True\n",
      "Image exists: True\n",
      "\n",
      "image 1/1 C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\test_images\\test_tumor.jpeg: 416x384 1 meningioma, 109.9ms\n",
      "Speed: 11.1ms preprocess, 109.9ms inference, 2.3ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Results saved to \u001b[1mruns\\detect\\predict5\u001b[0m\n",
      "Number of results: 1\n",
      "Detections: ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.9486])\n",
      "data: tensor([[120.1688,  97.2786, 170.1015, 153.0472,   0.9486,   2.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (239, 211)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[145.1351, 125.1629,  49.9327,  55.7686]])\n",
      "xywhn: tensor([[0.6878, 0.5237, 0.2366, 0.2333]])\n",
      "xyxy: tensor([[120.1688,  97.2786, 170.1015, 153.0472]])\n",
      "xyxyn: tensor([[0.5695, 0.4070, 0.8062, 0.6404]])\n",
      "Detected classes: ['meningioma']\n",
      "Results saved to \u001b[1mruns\\segment\\predict\u001b[0m\n",
      "YOLO output image saved at: C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\runs\\detect\\predict2\\test_tumor.jpeg\n",
      "YOLO output image not found. Directory contents: ['download (2).jpg']\n",
      "SAM output image saved at: C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\runs\\detect\\predict2\\sam_test_tumor.jpeg\n",
      "SAM output image not found. Directory contents: ['download (2).jpg']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from ultralytics import YOLO, SAM\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "model_path = \"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\runs\\\\detect\\\\train3\\\\weights\\\\best.pt\"\n",
    "image_path = \"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\test_images\\\\test_tumor.jpeg\"  # Changed to .jpg\n",
    "output_dir = \"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\runs\\\\detect\\\\predict2\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Verify paths\n",
    "print(\"Model exists:\", os.path.exists(model_path))\n",
    "print(\"Image exists:\", os.path.exists(image_path))\n",
    "\n",
    "# Load YOLO model and run inference\n",
    "yolo_model = YOLO(model_path)\n",
    "results = yolo_model(image_path, save=True, save_dir=output_dir, conf=0.05, verbose=True)\n",
    "\n",
    "# Print results\n",
    "print(\"Number of results:\", len(results))\n",
    "print(\"Detections:\", results[0].boxes if results[0].boxes else \"No detections\")\n",
    "if results[0].boxes:\n",
    "    print(\"Detected classes:\", [yolo_model.names[int(cls)] for cls in results[0].boxes.cls])\n",
    "\n",
    "# Load SAM model\n",
    "sam_model = SAM(\"sam2_b.pt\")\n",
    "\n",
    "# Process YOLO detections with SAM\n",
    "if results[0].boxes:\n",
    "    class_ids = results[0].boxes.cls.int().tolist()\n",
    "    boxes = results[0].boxes.xyxy\n",
    "    sam_results = sam_model(results[0].orig_img, bboxes=boxes, verbose=False, save=True, save_dir=output_dir, device=\"cpu\")\n",
    "\n",
    "    # Display YOLO output\n",
    "    yolo_output_filename = os.path.basename(image_path)\n",
    "    yolo_output_path = os.path.join(output_dir, yolo_output_filename)\n",
    "    print(\"YOLO output image saved at:\", yolo_output_path)\n",
    "\n",
    "    if os.path.exists(yolo_output_path):\n",
    "        img = cv2.imread(yolo_output_path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.title(\"YOLO Detection (Meningioma)\")\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Failed to load YOLO output image.\")\n",
    "    else:\n",
    "        print(\"YOLO output image not found. Directory contents:\", os.listdir(output_dir))\n",
    "\n",
    "    # Display SAM output\n",
    "    sam_output_filename = f\"sam_{os.path.basename(image_path)}\"  # SAM may prepend 'sam_'\n",
    "    sam_output_path = os.path.join(output_dir, sam_output_filename)\n",
    "    print(\"SAM output image saved at:\", sam_output_path)\n",
    "\n",
    "    if os.path.exists(sam_output_path):\n",
    "        img = cv2.imread(sam_output_path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.title(\"SAM Segmentation (Meningioma)\")\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Failed to load SAM output image.\")\n",
    "    else:\n",
    "        print(\"SAM output image not found. Directory contents:\", os.listdir(output_dir))\n",
    "else:\n",
    "    print(\"No detections to process with SAM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1da803-dd1c-473d-bde6-e3db98a18f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exists: True\n",
      "Image exists: False\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\test_images\\download(3).jpg does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mImage exists:\u001b[39m\u001b[33m\"\u001b[39m, os.path.exists(image_path))\n\u001b[32m     20\u001b[39m yolo_model = YOLO(model_path)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m results = \u001b[43myolo_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNumber of results:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(results))\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDetections:\u001b[39m\u001b[33m\"\u001b[39m, results[\u001b[32m0\u001b[39m].boxes \u001b[38;5;28;01mif\u001b[39;00m results[\u001b[32m0\u001b[39m].boxes \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mNo detections\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\engine\\model.py:185\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, source, stream, **kwargs)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    157\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    158\u001b[39m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image.Image, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np.ndarray, torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    159\u001b[39m     stream: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    160\u001b[39m     **kwargs: Any,\n\u001b[32m    161\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[32m    164\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    183\u001b[39m \u001b[33;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\engine\\model.py:555\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.predictor, \u001b[33m\"\u001b[39m\u001b[33mset_prompts\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[32m    554\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.set_prompts(prompts)\n\u001b[32m--> \u001b[39m\u001b[32m555\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor.predict_cli(source=source) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\engine\\predictor.py:227\u001b[39m, in \u001b[36mBasePredictor.__call__\u001b[39m\u001b[34m(self, source, model, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_inference(source, model, *args, **kwargs)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m         response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     40\u001b[39m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\engine\\predictor.py:300\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    296\u001b[39m     \u001b[38;5;28mself\u001b[39m.setup_model(model)\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:  \u001b[38;5;66;03m# for thread-safe inference\u001b[39;00m\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# Setup source every time predict is called\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msetup_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m     \u001b[38;5;66;03m# Check if save_dir/ label file exists\u001b[39;00m\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_txt:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\engine\\predictor.py:259\u001b[39m, in \u001b[36mBasePredictor.setup_source\u001b[39m\u001b[34m(self, source)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[33;03mSet up source and inference mode.\u001b[39;00m\n\u001b[32m    253\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    256\u001b[39m \u001b[33;03m        Source for inference.\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;28mself\u001b[39m.imgsz = check_imgsz(\u001b[38;5;28mself\u001b[39m.args.imgsz, stride=\u001b[38;5;28mself\u001b[39m.model.stride, min_dim=\u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# check image size\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m \u001b[38;5;28mself\u001b[39m.dataset = \u001b[43mload_inference_source\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;28mself\u001b[39m.source_type = \u001b[38;5;28mself\u001b[39m.dataset.source_type\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    268\u001b[39m     \u001b[38;5;28mself\u001b[39m.source_type.stream\n\u001b[32m    269\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.source_type.screenshot\n\u001b[32m    270\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset) > \u001b[32m1000\u001b[39m  \u001b[38;5;66;03m# many images\u001b[39;00m\n\u001b[32m    271\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33mvideo_flag\u001b[39m\u001b[33m\"\u001b[39m, [\u001b[38;5;28;01mFalse\u001b[39;00m]))\n\u001b[32m    272\u001b[39m ):  \u001b[38;5;66;03m# videos\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\data\\build.py:280\u001b[39m, in \u001b[36mload_inference_source\u001b[39m\u001b[34m(source, batch, vid_stride, buffer, channels)\u001b[39m\n\u001b[32m    278\u001b[39m     dataset = LoadPilAndNumpy(source, channels=channels)\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m     dataset = \u001b[43mLoadImagesAndVideos\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[38;5;66;03m# Attach source types to the dataset\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[38;5;28msetattr\u001b[39m(dataset, \u001b[33m\"\u001b[39m\u001b[33msource_type\u001b[39m\u001b[33m\"\u001b[39m, source_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ultralytics\\data\\loaders.py:373\u001b[39m, in \u001b[36mLoadImagesAndVideos.__init__\u001b[39m\u001b[34m(self, path, batch, vid_stride, channels)\u001b[39m\n\u001b[32m    371\u001b[39m         files.append(\u001b[38;5;28mstr\u001b[39m((parent / p).absolute()))  \u001b[38;5;66;03m# files (relative to *.txt file parent)\u001b[39;00m\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# Define files as images or videos\u001b[39;00m\n\u001b[32m    376\u001b[39m images, videos = [], []\n",
      "\u001b[31mFileNotFoundError\u001b[39m: C:\\Users\\Usman Pc\\Desktop\\SANA\\sam2_yolo11\\sam_yolo11\\test_images\\download(3).jpg does not exist"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from ultralytics import YOLO, SAM\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "model_path = \"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\runs\\\\detect\\\\train3\\\\weights\\\\best.pt\"\n",
    "image_path = \"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\sam_yolo11\\test_images\\tumor.jpeg\" \n",
    "output_dir = \"C:\\\\Users\\\\Usman Pc\\\\Desktop\\\\SANA\\\\sam2_yolo11\\\\sam_yolo11\\\\runs\\\\segment\\\\predict2\"\n",
    "\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"Model exists:\", os.path.exists(model_path))\n",
    "print(\"Image exists:\", os.path.exists(image_path))\n",
    "\n",
    "\n",
    "yolo_model = YOLO(model_path)\n",
    "results = yolo_model(image_path, save=True, save_dir=output_dir, conf=0.05, verbose=True)\n",
    "\n",
    "\n",
    "print(\"Number of results:\", len(results))\n",
    "print(\"Detections:\", results[0].boxes if results[0].boxes else \"No detections\")\n",
    "if results[0].boxes:\n",
    "    print(\"Detected classes:\", [yolo_model.names[int(cls)] for cls in results[0].boxes.cls])\n",
    "\n",
    "\n",
    "sam_model = SAM(\"sam2_b.pt\")\n",
    "\n",
    "\n",
    "if results[0].boxes:\n",
    "    class_ids = results[0].boxes.cls.int().tolist()\n",
    "    boxes = results[0].boxes.xyxy\n",
    "    sam_results = sam_model(results[0].orig_img, bboxes=boxes, verbose=False, save=True, save_dir=output_dir, device=\"cpu\")\n",
    "\n",
    "    \n",
    "    yolo_output_filename = os.path.basename(image_path)\n",
    "    yolo_output_path = os.path.join(output_dir, yolo_output_filename)\n",
    "    print(\"YOLO output image saved at:\", yolo_output_path)\n",
    "\n",
    "    if os.path.exists(yolo_output_path):\n",
    "        img = cv2.imread(yolo_output_path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.title(\"YOLO Detection (Meningioma)\")\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Failed to load YOLO output image.\")\n",
    "    else:\n",
    "        print(\"YOLO output image not found. Directory contents:\", os.listdir(output_dir))\n",
    "\n",
    "   \n",
    "    sam_output_filename = f\"sam_{os.path.basename(image_path)}\"  # SAM may prepend 'sam_'\n",
    "    sam_output_path = os.path.join(output_dir, sam_output_filename)\n",
    "    print(\"SAM output image saved at:\", sam_output_path)\n",
    "\n",
    "    if os.path.exists(sam_output_path):\n",
    "        img = cv2.imread(sam_output_path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.title(\"SAM Segmentation (Meningioma)\")\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Failed to load SAM output image.\")\n",
    "    else:\n",
    "        print(\"SAM output image not found. Directory contents:\", os.listdir(output_dir))\n",
    "else:\n",
    "    print(\"No detections to process with SAM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8655810c-db58-4a7d-80d8-537f033e2a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
